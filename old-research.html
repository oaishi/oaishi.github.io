<!doctype html>
<html lang="en">

<head>
	<!-- Required meta tags -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=yes">
	<link rel="icon" href="img/favicon.png" type="image/png">
	<title>Faria Huq</title>
	<!-- Bootstrap CSS -->
	<link rel="stylesheet" href="css/bootstrap.css">
	<link rel="stylesheet" href="vendors/linericon/style.css">
	<link rel="stylesheet" href="css/font-awesome.min.css">
	<link rel="stylesheet" href="vendors/owl-carousel/owl.carousel.min.css">
	<link rel="stylesheet" href="css/magnific-popup.css">
	<link rel="stylesheet" href="vendors/nice-select/css/nice-select.css">
	<!-- main css -->
	<link rel="stylesheet" href="css/style.css">
</head>

<body class="blog_version">

	<!--================ Start Header Area =================-->
	<header class="header_area">
		<div class="main_menu">
			<nav class="navbar navbar-expand-lg navbar-light">
				<div class="container">
					<!-- Brand and toggle get grouped for better mobile display -->
					<a class="navbar-brand logo_h" href="index.html"><img src="img/logo.png" alt=""></a>
					<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
					 aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
					<!-- Collect the nav links, forms, and other content for toggling -->
					<div class="collapse navbar-collapse offset" id="navbarSupportedContent">
						<ul class="nav navbar-nav menu_nav justify-content-end">
							<li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
							<li class="nav-item active"><a class="nav-link" href="research.html">Research</a></li>
							<li class="nav-item"><a class="nav-link" href="projects.html">Projects</a></li>							
							<li class="nav-item"><a class="nav-link" href="achievements.html">Hackathons</a></li>
							<li class="nav-item"><a class="nav-link" href="skill.html">Skills</a></li>							
							<li class="nav-item"><a class="nav-link" href="handicrafts.html">Upcycling</a></li>
							<li class="nav-item"><a class="nav-link" href="blogs.html">Blog</a></li>
							<!--li class="nav-item submenu dropdown">
								<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true"
								 aria-expanded="false">Others</a>
								<ul class="dropdown-menu">
									<li class="nav-item"><a class="nav-link" href="blogs.html">Blog</a></li>
									<li class="nav-item"><a class="nav-link" href="handicrafts.html">Handicraft</a></li>
								</ul>
							</li-->
							
						</ul>
					</div>
				</div>
			</nav>
		</div>
	</header>
	<!--================ End Header Area =================-->

    <!--================ Start Banner Area =================-->
    <section class="home_banner_area">
		<div class="banner_inner">
			<div class="container">
				<div class="row">
					<div class="col-lg-7">
						<div class="banner_content">
							<h1 class="text-uppercase">Research</h1>
						</div>
					</div>
				</div>
			</div>
		</div>
	</section>
    <!--================ End Banner Area =================-->
        
	
	<section class="portfolio_details_area">
        <div class="container">
		
			<h1 class="text-heading title_color">Completed Works</h1>
			
			<p class="sample-text">
				<!--i>(Few works are hidden for double-blind submission policy) </i--> 
			</p>
			
			<!--graphiti-->
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
                            <iframe width="400" height="350" src="https://www.youtube.com/embed/_xzTAlP0NnQ" frameborder="0" 
							allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Embodied Graph Analytics</h5>
                            <p>
								<i>(Accepted to CHI '22, acceptance rate: 12.5%)</i></br>
								<i class="fa fa-github-alt" style="font-size: 24px;"></i><a href="https://github.com/nsaquib/Embodied-Graphs" ><span>Code</span></a> |</a> <a href='javascript:void();' onclick="myFunction0()">Abstract</a>
								<br>
								Dr. Nazmus Saquib, <b style="color:black">Faria Huq</b>, Dr. Syed Arefinul Haque </br>								
								<i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Sketching Interface, Embodied Mathematics, Graph Analytics, Computer Graphics, Computer Vision, Image Processing
                            </p>
							
							<div style="display: none;" id="myDIV0">
								<p>                                
									Graph and network analytics are mostly performed using a combination of symbolic expressions, code, and graph visualizations. 
									These different representations enable graph-oriented conceptualization, analytics, and presentation of relationships in networks.
									While many visualization designs are implemented for visual understanding of graphs, they tend to be designed for custom 
									applications, and do not facilitate graph algebra. We define a design space of general graph analytics by summarizing 
									the commonly used graphical representations (graphs, simplicial complexes, and hypergraphs) and graph operations, 
									and map these elements to three brushes and some direct manipulation techniques.
								</p>
							</div>
                        </div>
                    </div>
                </div>
                
            </div>
				
			<!--review4repair-->
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
							</br>
                            <img class="img-fluid" src="img/research/review.png" alt="">
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Review4Repair: Code Review Aided Automatic Program Repairing</h5>
                            <p>
								<i>(Published in <a href="https://www.journals.elsevier.com/information-and-software-technology"> Information and Software Technology </a>)</i></br>
								<i class="fa fa-file-pdf-o" style="font-size: 24px;"></i> <a href="https://doi.org/10.1016/j.infsof.2021.106765" ><span>Doi </span> |</a> <a href='javascript:void();' onclick="myFunction1()">Abstract</a>
								<br>
                                <b style="color:black">Faria Huq</b>, Masum Hasan, Mahim Anzum Haque Pantho, Sazan Mahbub, 
								Prof. Anindya Iqbal, Touﬁque Ahmed
								<br>
								<i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Automatic Program Repair, Natural Language Processing

								<!--/br>
								<a class="primary_btn" href="#"><span>View Details</span></a-->
                            </p>
							
							<div style="display: none;" id="myDIV1">
								<p>
									The natural language instructions scripted on the review comments are
									enormous sources of information about code bug’s nature and expected solutions.
									In this study, we investigate the performance improvement of repair techniques using code review comments.
									We train a sequence-to-sequence model on 55,060 code reviews and
									associated code changes. We also introduce new tokenization and preprocessing approaches 
									that help to achieve significant improvement over state-of-the-art
									learning-based repair techniques. We boost the top-1 accuracy by 20.33% and top-10 accuracy by 34.82%.
									We could provide a suggestion for stylistics and non-code errors unaddressed by
									prior techniques.
								</p>
							</div>


                            
                        </div>
                    </div>
                </div>
                
            </div>
			
			<!--text2scene-->
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
                            <iframe width="400" height="350" src="https://www.youtube.com/embed/kLDdtmornOQ" frameborder="0" 
							allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Static and Animated 3D Scene Generation from Free-form Text Descriptions</h5>
                            <p>
								<i>(Preparing Manuscript for submission )</i></br>
								<i class="fa fa-file-pdf-o" style="font-size: 24px;"></i> <a href="https://arxiv.org/abs/2010.01549" ><span>Preprint</span></a> | 
								<i class="fa fa-github-alt" style="font-size: 24px;"></i><a href="https://github.com/oaishi/3DScene_from_text" ><span>Code</span></a> |</a> <a href='javascript:void();' onclick="myFunction2()">Abstract</a>
								<br>
								<b style="color:black">Faria Huq</b>, Prof. Anindya Iqbal, Nafees Ahmed
								</br>
								<i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Natural Language Processing, Computer Graphics

                            </p>


							<div style="display: none;" id="myDIV2">	
									<p>
										Generating coherent and useful image/video scenes from a free-form textual description is technically a 
										very difficult problem to handle. Textual description of the same scene can vary greatly from person to person, 
										or sometimes even for the same person from time to time. As the choice of words and syntax vary while preparing a 
										textual description, it is challenging for the system to reliably produce a consistently desirable output from
										different forms of language input. In our work, we study
										a new pipeline that aims to generate static as well as animated 3D scenes from different types of free-form textual
										scene description without any major restriction. Our work shows a proof 
										of concept of one approach towards solving the problem, and we believe with enough training data, the same pipeline can 
										be expanded to handle even broader set of 3D scene generation problems.
									</p>
							</div>


                            
                        </div>
                    </div>
                </div>
                
            </div>
        
			<!--citadel-->
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
							</br>
                            <img class="img-fluid" src="img/research/citadel.gif" alt="" width="500" height="350"></img>
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">A Tale on Abuse and Its Detection over Online Platforms, Especially over Emails: From the Context of Bangladesh</h5>
                            <p>	
								<i>(Accepted in NSyss' 21, acceptance rate: 16.67%)</i></br>
								<i class="fa fa-github-alt" style="font-size: 24px;"></i><a href="https://github.com/oaishi/AbuseDetector-Server" ><span>Code</span></a> |</a> <a href='javascript:void();' onclick="myFunction3()">Abstract</a>
								<br>
                                Ishita Haque, Rudaiba Adnin, Sadia Afroz, <b style="color:black">Faria Huq</b>, Sazan Mahbub, Prof. A. B. M. Alim Al Islam  
								</br>
								
								<i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Interactive System, Natural Language Processing
                            </p>

							<div style="display: none;" id="myDIV3">
								<p>
									With the rise of interactive online platforms, online abuse is becoming more and more prevalent. To gain rich insights
									on the user’s experience with abusive behaviors over emailing and other online platforms,
									we conducted a semi-structured interview with our participants. Through our user studies, we confirm a noteworthy
									demand to explore abuse detection over emails. Here, we
									reveal a clear preference from the users for an automated abuse detection system over a human-moderator based
									system. These findings, along with the existing limited effort for abusive behavior detection and prevention
									systems for emails inspire us to design and build "Citadel", which is a fully automated abuse detection system in
									the form of a Chrome extension.
								</p>
							</div>


                            
                        </div>
                    </div>
                </div>
                
            </div>
        	
            <h1 class="text-heading title_color">Current Works </h1> 
            
			<!--Fmap-->
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
							</br>
                            <img class="img-fluid" src="img/research/fmap.gif" alt="">
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">3D Shape Correspondence via Probabilistic Synchronization of Functional Maps and Riemannian Geometry</h5>
                            <p>
								<b style="color:black">Faria Huq</b>, Sahra Yusuf, Berna Kabadayi, Dr. Dena Bazazian, Dr. Tolga Birdal, Prof. Nina Miolane</br>	
								<i class="fa fa-rss" style="font-size: 24px;"></i><a href="http://summergeometry.org/sgi2021/3d-shape-correspondence-via-probabilistic-synchronization-of-functional-maps-and-riemannian-geometry/" ><span>Blog Post</span></a> |</a> <a href='javascript:void();' onclick="myFunction4()">Abstract</a>
								<br>															
								<i class="fa fa-calendar"  style="font-size: 12px;"></i> Expected date of completion: February, 2022
                                <br>
                                <i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Riemannian Geometry, Permutation Synchronization
                            </p>

							<div style="display: none;" id="myDIV4">
								<p>                                
									This project is about probabilistic correspondence synchronization, a state of the art technique in multi-way matching of a collection 
									of 3D shapes usually represented as nodes in a graph. 
									In particular, we will model correspondences via functional maps and build upon the prior work on permutation synchronization
								</p>
							</div>
							

							
                        </div>
                    </div>
                </div>
                
            </div>
			
			<!--Tal-->
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
							</br>
                            <img class="img-fluid" src="img/research/tal_project.gif" alt="">
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Self-similarity loss for shape descriptor learning in correspondence problems</h5>
                            <p>
								<b style="color:black">Faria Huq</b>, Kinjal Parikh, Lucas Valenca, Dr. Tal Shnitzer-Dery </br>	
								<!--i class="fa fa-github-alt" style="font-size: 24px;"></i><a href="https://github.com/Tero-Labs/Embodied_vector_analytics" ><span>Code</span></a!-->
								<br>
								</a> <a href='javascript:void();' onclick="myFunction5()">Abstract</a>
								<br>															
								<i class="fa fa-calendar"  style="font-size: 12px;"></i> Expected date of completion: March, 2022
                                <br>
                                <i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Deep Learning, Unsupervised Learning
                            </p>
							<div style="display: none;" id="myDIV5">
								<p>                                
									Recent work on shape correspondence using functional maps developed several unsupervised frameworks
									for learning better shape descriptors for correspondence. One of the challenges in such shape 
									correspondence tasks stems from symmetric ambiguity, where different shape regions are represented 
									similarly due to symmetry and are therefore wrongly matched. In an attempt to address this challenge, 
									we will explore the use of a recently introduced contextual loss function.
								</p>
							</div>
							
                        </div>
                    </div>
                </div>
                
            </div>
			
			<!--OptimalTransport-->
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
							</br>
                            <img class="img-fluid" src="img/research/aniso_ellipse.gif" alt="">
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Anisotropic Schrödinger Bridges</h5>
                            <p>
								<b style="color:black">Faria Huq</b>, Jonathan Mousley, Juan Atehortúa, Adrish Dey, Prof. Justin Solomon</br>	
								<!--i class="fa fa-github-alt" style="font-size: 24px;"></i><a href="https://github.com/Tero-Labs/Embodied_vector_analytics" ><span>Code</span></a!-->
								<br>	
								</a> <a href='javascript:void();' onclick="myFunction6()">Abstract</a>
									
									<br>															
								<i class="fa fa-calendar"  style="font-size: 12px;"></i> Expected date of completion: December, 2021
                                <br>
                                <i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Optimal Transport, Anisotropic Diffusion, Schrödinger Bridges
                            </p>

							<div style="display: none;" id="myDIV6">
								<p>                                
									In this project, we mplemented a discrete Schrödinger bridge model for anisotropic heat diffusion, biasing it to move along different paths on the surface, targeting
									applications in geometry processing. Currently, we are trying to optimize for the anisotropy
									of our operator to add constraints on the transport problem.
								</p>
							</div>

							
                        </div>
                    </div>
                </div>
                
            </div>
			
			<!--EmbodiedVector-->
            <div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
							</br>
                            <img class="img-fluid" src="img/research/vector.gif" alt="">
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Embodied Vector Algebra</h5>
                            <p>
								<b style="color:black">Faria Huq</b>, Dr. Nazmus Saquib </br>	
								<i class="fa fa-github-alt" style="font-size: 24px;"></i><a href="https://github.com/Tero-Labs/Embodied_vector_analytics" ><span>Code</span></a> |</a> <a href='javascript:void();' onclick="myFunction7()">Abstract</a>
								<br>															
								<i class="fa fa-calendar"  style="font-size: 12px;"></i> Expected date of completion: May, 2021
                                <br>
                                <i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Sketching Interface, Embodied Mathematics, Vector Analytics, Computer Graphics
                            </p>

							
							<div style="display: none;" id="myDIV7">
								<p>                                
									This is a work in progress. So far we have developed the basic interactions for drawing and modifying vectors. 
									Currently we are working on the implementation of basic vector functions.
								</p>
							</div>

							
                        </div>
                    </div>
                </div>
                
            </div>
						
			<h1 class="text-heading title_color">Other Works I contributed to</h1>        		
			
			<!--Synsin-->
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
							</br>
                            <img class="img-fluid" src="img/research/blur_to_clean.gif" alt="">
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Novel View Synthesis from blurred image</h5>
                            <p>
								<b style="color:black">Faria Huq</b>, Prof. Anindya Iqbal, Nafees Ahmed
								</br>
								<i class="fa fa-cogs"  style="font-size: 24px;"></i><a href="deblur.html" ><span> Project Page</span></a> |</a> <a href='javascript:void();' onclick="myFunction8()">Abstract</a>
								</br>
								<i class="fa fa-calendar"  style="font-size: 12px;"></i> Expected date of completion: March, 2022
								<br>
								<i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Neural Rendering, View Synthesis, Image Deblurring
                            </p>
							<div style="display: none;" id="myDIV8">
								<p>
									We aim to synthesize a target image with an arbitrary target camera pose (novel view synthesis) from given a source
									image of a dynamic scene containing motion blur and its camera pose. 
									Our key insight is to utilize neural rendering to jointly remove motion blur artifact using 
									deblurring technique and synthesize novel views from high-dimensional spatial feature vectors.
									We are using <a href="https://stereoblur.shangchenzhou.com/">Stereo Blur Dataset</a> for our experimental analysis. 
   
							   </p>
							</div>
							
                        </div>
                    </div>
                </div>
                
            </div>
			
			<!--I3D-->
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
							</br>
                            <img class="img-fluid" src="img/research/abuse.gif" alt=""><a href="https://www.crcv.ucf.edu/projects/real-world/">source</a></img> 
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Real-world Anomaly Detection in Surveillance Videos by Analyzing Human Pose and Motion</h5>
                            <p>								
                                <b style="color:black">Faria Huq</b>, Protik Bose, Sifat Ishmam, Syed Zami Ul Haque, Sazan Mahbub, Prof. Mohammad Saifur Rahman  
								</br>
								</a> <a href='javascript:void();' onclick="myFunction9()">Abstract</a>
								<br>
								<i class="fa fa-calendar"  style="font-size: 12px;"></i> Expected date of completion: April, 2022
								<br>
								<i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Explainable AI, Human Pose and Body Keypoints Analysis, Video Understanding
                            </p>

							<div style="display: none;" id="myDIV9">
								<p>
									We propose to investigate the relation of human pose with anomalous activities by utilizing human body keypoints. 
									We are building an attention based hierarchical Multi Instance Learning (MIL) model to analyze and interpret anomalous human 
									activities in a real-world surveillance Videos using the dataset proposed by <a href="https://www.crcv.ucf.edu/projects/real-world/"><i>Sultani et al.</i></a>
							   </p>
							</div>

                            
                        </div>
                    </div>
                </div>
                
            </div>
        	
			
		    		
			
		</div>
    </section>
    <!--================End Portfolio Details Area =================-->
        
    <!-- Start Tag Area -->
	<div class="whole-wrap">
		<div class="container">
		
			<div class="section-top-border">
				<h3 class="mb-30 title_color">Research Topics</h3>
				<div class="row">
					<div class="col-lg-12">
						<blockquote class="generic-blockquote">
							<a class="tagTopic" href="portfolio.html">#Computer Graphics</a>, #Interaction, #Sketching, #Augmented and Virtual Reality,
							#Computer Vision, #Visual Communication, #Visual Art,
							#3D vision, #Computational Photography, #Image & Video Understanding, #Neural Rendering,
							#Generative AI, #Natural Language Processing
						</blockquote>
					</div>
				</div>
			</div>
			
		</div>
	</div>		
	<!-- End Tag Area -->
		
	    
    <!--================Footer Area =================-->
	<footer class="footer_area">
        <div class="container">
            <div class="row justify-content-center">
                <div class="col-lg-12">
                    <div class="footer_top flex-column">
                        <div class="footer_logo">
                            <a href="#">
                                <img src="img/logo.png" alt="">
                            </a>
                            <h4>Contact</h4>
                        </div>
                        <div class="footer_social">
                            <a href="https://twitter.com/FariaHuqOaishi"><i class="fa fa-twitter"></i></a>
							<a href="https://www.linkedin.com/in/faria-huq-058b2a145/"><i class="fa fa-linkedin"></i></a>
							<a href="https://github.com/oaishi"><i class="fa fa-github"></i></a>
							<a href="https://www.instagram.com/diy_of_oaishi/"><i class="fa fa-instagram"></i></a>
                        </div>
                    </div>
                </div>
            </div>
            <div class="row footer_bottom justify-content-center">
                <p class="col-lg-8 col-sm-12 footer-text">
                    <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
Copyright &copy;<script>document.write(new Date().getFullYear());</script> Faria Huq | Based on a template by <a href="https://colorlib.com" target="_blank">Colorlib</a>
<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --></p>
            </div>
        </div>
    </footer>
    <!--================End Footer Area =================-->
    
		<!-- Optional JavaScript -->
		<!-- jQuery first, then Popper.js, then Bootstrap JS -->
		<script src="js/jquery-3.2.1.min.js"></script>
		<script src="js/popper.js"></script>
		<script src="js/bootstrap.min.js"></script>
		<script src="js/stellar.js"></script>
		<script src="vendors/lightbox/simpleLightbox.min.js"></script>
		<script src="vendors/nice-select/js/jquery.nice-select.min.js"></script>
		<script src="vendors/isotope/imagesloaded.pkgd.min.js"></script>
		<script src="vendors/isotope/isotope-min.js"></script>
		<script src="vendors/owl-carousel/owl.carousel.min.js"></script>
		<script src="js/jquery.ajaxchimp.min.js"></script>
		<script src="js/mail-script.js"></script>
		<script src="js/theme.js"></script>

		<script>
			function myFunction0() {
			  var x = document.getElementById("myDIV0");
			  if (x.style.display === "none") {
				x.style.display = "block";
			  } else {
				x.style.display = "none";
			  }
			}
		
			function myFunction1() {
			  var x = document.getElementById("myDIV1");
			  if (x.style.display === "none") {
				x.style.display = "block";
			  } else {
				x.style.display = "none";
			  }
			}

			function myFunction2() {
			  var x = document.getElementById("myDIV2");
			  if (x.style.display === "none") {
				x.style.display = "block";
			  } else {
				x.style.display = "none";
			  }
			}

			function myFunction3() {
			  var x = document.getElementById("myDIV3");
			  if (x.style.display === "none") {
				x.style.display = "block";
			  } else {
				x.style.display = "none";
			  }
			}

			function myFunction4() {
			  var x = document.getElementById("myDIV4");
			  if (x.style.display === "none") {
				x.style.display = "block";
			  } else {
				x.style.display = "none";
			  }
			}

			function myFunction5() {
			  var x = document.getElementById("myDIV5");
			  if (x.style.display === "none") {
				x.style.display = "block";
			  } else {
				x.style.display = "none";
			  }
			}


			function myFunction6() {
			  var x = document.getElementById("myDIV6");
			  if (x.style.display === "none") {
				x.style.display = "block";
			  } else {
				x.style.display = "none";
			  }
			}

			function myFunction7() {
			  var x = document.getElementById("myDIV7");
			  if (x.style.display === "none") {
				x.style.display = "block";
			  } else {
				x.style.display = "none";
			  }
			}


			function myFunction8() {
			  var x = document.getElementById("myDIV8");
			  if (x.style.display === "none") {
				x.style.display = "block";
			  } else {
				x.style.display = "none";
			  }
			}


			function myFunction9() {
			  var x = document.getElementById("myDIV9");
			  if (x.style.display === "none") {
				x.style.display = "block";
			  } else {
				x.style.display = "none";
			  }
			}


			</script>

			
	</body>
</html>
<!doctype html>
<html lang="en">

<head>
	<!-- Required meta tags -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<link rel="icon" href="img/favicon.png" type="image/png">
	<title>Faria Huq</title>
	<!-- Bootstrap CSS -->
	<link rel="stylesheet" href="css/bootstrap.css">
	<link rel="stylesheet" href="vendors/linericon/style.css">
	<link rel="stylesheet" href="css/font-awesome.min.css">
	<link rel="stylesheet" href="vendors/owl-carousel/owl.carousel.min.css">
	<link rel="stylesheet" href="css/magnific-popup.css">
	<link rel="stylesheet" href="vendors/nice-select/css/nice-select.css">
	<!-- main css -->
	<link rel="stylesheet" href="css/style.css">
</head>

<body class="blog_version">

	<!--================ Start Header Area =================-->
	<header class="header_area">
		<div class="main_menu">
			<nav class="navbar navbar-expand-lg navbar-light">
				<div class="container">
					<!-- Brand and toggle get grouped for better mobile display -->
					<a class="navbar-brand logo_h" href="index.html"><img src="img/logo.png" alt=""></a>
					<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
					 aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
					<!-- Collect the nav links, forms, and other content for toggling -->
					<div class="collapse navbar-collapse offset" id="navbarSupportedContent">
						<ul class="nav navbar-nav menu_nav justify-content-end">
							<li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
							<li class="nav-item active"><a class="nav-link" href="research.html">Research</a></li>
							<li class="nav-item"><a class="nav-link" href="projects.html">Projects</a></li>							
							<li class="nav-item"><a class="nav-link" href="achievements.html">Achievements</a></li>
							<li class="nav-item"><a class="nav-link" href="skill.html">Skills</a></li>							
							<li class="nav-item"><a class="nav-link" href="handicrafts.html">Upcycling</a></li>
							<li class="nav-item"><a class="nav-link" href="blogs.html">Blog</a></li>
							<!--li class="nav-item submenu dropdown">
								<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true"
								 aria-expanded="false">Others</a>
								<ul class="dropdown-menu">
									<li class="nav-item"><a class="nav-link" href="blogs.html">Blog</a></li>
									<li class="nav-item"><a class="nav-link" href="handicrafts.html">Handicraft</a></li>
								</ul>
							</li-->
							
						</ul>
					</div>
				</div>
			</nav>
		</div>
	</header>
	<!--================ End Header Area =================-->

    <!--================ Start Banner Area =================-->
    <section class="home_banner_area">
		<div class="banner_inner">
			<div class="container">
				<div class="row">
					<div class="col-lg-7">
						<div class="banner_content">
							<h1 class="text-uppercase">Research</h1>
						</div>
					</div>
				</div>
			</div>
		</div>
	</section>
    <!--================ End Banner Area =================-->
        
	
	<section class="portfolio_details_area">
        <div class="container">
		
			<h1 class="text-heading title_color">Completed Works</h1>
			
			<!--p class="sample-text">
				<i>(Few works are hidden for double blind submission process) </i> 
			</p-->
						
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
							</br>
                            <img class="img-fluid" src="img/research/review.png" alt="">
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Review4Repair: Code Review Aided Automatic Program Repairing</h5>
                            <p>
								<i>( Currently Under Review at <a href="https://www.journals.elsevier.com/information-and-software-technology"> Information and Software Technology </a>)</i></br>
								<i class="fa fa-file-pdf-o" style="font-size: 24px;"></i> <a href="https://arxiv.org/abs/2010.01544" ><span>Preprint</span></a> 
								<br>
                                <b style="color:black">Faria Huq</b>, Masum Hasan, Mahim Anzum Haque Pantho, Sazan Mahbub, 
								Dr.Anindya Iqbal, Touﬁque Ahmed
								<br>
								<i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Automatic Program Repair, Natural Language Processing

								<!--/br>
								<a class="primary_btn" href="#"><span>View Details</span></a-->
                            </p>
                            <p>
                                The natural language instructions scripted on the review comments are
								enormous sources of information about code bug’s nature and expected solutions.
								In this study, we investigate the performance improvement of repair techniques using code review comments.
								We train a sequence-to-sequence model on 55,060 code reviews and
								associated code changes. We also introduce new tokenization and preprocessing approaches 
								that help to achieve significant improvement over state-of-the-art
								learning-based repair techniques. We boost the top-1 accuracy by 20.33% and top-10 accuracy by 34.82%.
								We could provide a suggestion for stylistics and non-code errors unaddressed by
								prior techniques.
                            </p>
                        </div>
                    </div>
                </div>
                
            </div>
			
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
                            <iframe width="400" height="350" src="https://www.youtube.com/embed/kLDdtmornOQ" frameborder="0" 
							allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Static and Animated 3D Scene Generation from Free-form Text Descriptions</h5>
                            <p>
								<i>( Currently Under Review at <a href="https://www.mdpi.com/journal/jimaging"> MDPI Journal of Imaging </a>)</i></br>								
								<i class="fa fa-file-pdf-o" style="font-size: 24px;"></i> <a href="https://arxiv.org/abs/2010.01549" ><span>Preprint</span></a> | 
								<i class="fa fa-github-alt" style="font-size: 24px;"></i><a href="https://github.com/oaishi/3DScene_from_text" ><span>Code</span></a>
								<br>
								<b style="color:black">Faria Huq</b>, Dr.Anindya Iqbal, Nafees Ahmed
								</br>
								<i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Natural Language Processing, Computer Graphics

                            </p>
                            <p>
                                Generating coherent and useful image/video scenes from a free-form textual description is technically a 
								very difficult problem to handle. Textual description of the same scene can vary greatly from person to person, 
								or sometimes even for the same person from time to time. As the choice of words and syntax vary while preparing a 
								textual description, it is challenging for the system to reliably produce a consistently desirable output from
								different forms of language input. In our work, we study
								a new pipeline that aims to generate static as well as animated 3D scenes from different types of free-form textual
								scene description without any major restriction. Our work shows a proof 
								of concept of one approach towards solving the problem, and we believe with enough training data, the same pipeline can 
								be expanded to handle even broader set of 3D scene generation problems.
                            </p>
                        </div>
                    </div>
                </div>
                
            </div>
        
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
							</br>
                            <img class="img-fluid" src="img/research/citadel.gif" alt="" width="500" height="350"></img>
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Citadel: An Automated Abuse Detection System to Detect and Prevent Abusive Behaviors over Emails</h5>
                            <p>	
								<i>( Preparing Manuscript for submission )</i></br>
								<i class="fa fa-github-alt" style="font-size: 24px;"></i><a href="https://github.com/oaishi/AbuseDetector-Server" ><span>Code</span></a>
								<br>
                                Ishita Haque, Rudaiba Adnin, Sadia Afroz, <b style="color:black">Faria Huq</b>, Sazan Mahbub, Dr. A. B. M. Alim Al Islam  
								</br>
								
								<i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Interactive System, Natural Language Processing
                            </p>
                            <p>
                                With the rise of interactive online platforms, online abuse is becoming more and more prevalent. To gain rich insights
								on the user’s experience with abusive behaviors over emailing and other online platforms,
								we conducted a semi-structured interview with our participants. Through our user studies, we confirm a noteworthy
								demand to explore abuse detection over emails. Here, we
								reveal a clear preference from the users for an automated abuse detection system over a human-moderator based
								system. These findings, along with the existing limited effort for abusive behavior detection and prevention
								systems for emails inspire us to design and build "Citadel", which is a fully automated abuse detection system in
								the form of a Chrome extension.
							</p>
                        </div>
                    </div>
                </div>
                
            </div>
        	
      
			<h1 class="text-heading title_color">Ongoing Works</h1>
        
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
							</br>
                            <img class="img-fluid" src="img/research/sketching.gif" alt="">
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Embodied Graph By Interactive Sketching</h5>
                            <p>
								<b style="color:black">Faria Huq</b>, Dr.Nazmus Saquib
								</br>
								<i class="fa fa-calendar"  style="font-size: 12px;"></i> Expected date of completion: January, 2021
								<br>
								<i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Interactive System, Sketching Interface, Symbolic Mathematics, Graph Analysis
                            </p>
							<p>
                                 We aim to develop a design framework and an interactive sketch interface to combine different graph 
								 operations with layers of sketched, visually interpretable compositions. 
								 This is a work in progress. So far we have developed the basic interactions for drawing and modifying graphs.
								 Currently we are working on the implementation of basic graph algorithms. 

                            </p>
                        </div>
                    </div>
                </div>
                
            </div>
			
			
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
							</br>
                            <img class="img-fluid" src="img/research/blur_to_clean.gif" alt="">
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Novel View Synthesis from blurred image</h5>
                            <p>
								<b style="color:black">Faria Huq</b>, Dr.Anindya Iqbal, Nafees Ahmed
								</br>
								<i class="fa fa-cogs"  style="font-size: 24px;"></i><a href="deblur.html" ><span> Project Page</span></a>
								</br>
								<i class="fa fa-calendar"  style="font-size: 12px;"></i> Expected date of completion: March, 2021
								<br>
								<i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Neural Rendering, View Synthesis, Image Deblurring
                            </p>
							<p>
                                 We aim to synthesize a target image with an arbitrary target camera pose (novel view synthesis) from given a source
								 image of a dynamic scene containing motion blur and its camera pose. 
								 Our key insight is to utilize neural rendering to jointly remove motion blur artifact using 
								 deblurring technique and synthesize novel views from high-dimensional spatial feature vectors.
								 We are using <a href="https://stereoblur.shangchenzhou.com/">Stereo Blur Dataset</a> for our experimental analysis. 

                            </p>
                        </div>
                    </div>
                </div>
                
            </div>
			
			<div class="portfolio_details_inner">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="left_img">
							</br>
                            <img class="img-fluid" src="img/research/abuse.gif" alt=""><a href="https://www.crcv.ucf.edu/projects/real-world/">source</a></img>
                        </div>
                    </div>
                    <div class="offset-lg-1 col-lg-7">
                        <div class="portfolio_right_text mt-30">
                            <h5 class="text-uppercase">Real-world Anomaly Detection in Surveillance Videos by Analyzing Human Pose and Motion</h5>
                            <p>								
                                <b style="color:black">Faria Huq</b>, Protik Bose, Sifat Ishmam, Syed Zami Ul Haque, Sazan Mahbub, Dr. Mohammad Saifur Rahman  
								</br>
								<i class="fa fa-calendar"  style="font-size: 12px;"></i> Expected date of completion: April, 2021
								<br>
								<i class="fa fa-tags"  style="font-size: 12px;"></i> Keywords: Explainable AI, Human Pose and Body Keypoints Analysis, Video Understanding
                            </p>
                            <p>
                                 We propose to investigate the relation of human pose with anomalous activities by utilizing human body keypoints. 
								 We are building an attention based hierarchical Multi Instance Learning (MIL) model to analyze and interpret anomalous human 
								 activities in a real-world surveillance Videos using the dataset proposed by <a href="https://www.crcv.ucf.edu/projects/real-world/"><i>Sultani et al.</i></a>
                            </p>
                        </div>
                    </div>
                </div>
                
            </div>
        	
			
		    		
			
		</div>
    </section>
    <!--================End Portfolio Details Area =================-->
        
    <!-- Start Align Area -->
	<div class="whole-wrap">
		<div class="container">
		
			<div class="section-top-border">
				<h3 class="mb-30 title_color">Research Topics</h3>
				<div class="row">
					<div class="col-lg-12">
						<blockquote class="generic-blockquote">
							#Generative AI, #Natural Language Processing, #Computer Vision, #Visual Communication, #Visual Art,
							#3D vision, #Computational Photography, 
							#Computer Graphics, #Interaction, #Sketching, #Image & Video Understanding, #Neural Rendering, 
							#AR/VR
						</blockquote>
					</div>
				</div>
			</div>
			
		</div>
	</div>		
	<!-- End Align Area -->
		
	    
    <!--================Footer Area =================-->
	<footer class="footer_area">
        <div class="container">
            <div class="row justify-content-center">
                <div class="col-lg-12">
                    <div class="footer_top flex-column">
                        <div class="footer_logo">
                            <a href="#">
                                <img src="img/logo.png" alt="">
                            </a>
                            <h4>Contact</h4>
                        </div>
                        <div class="footer_social">
                            <a href="https://twitter.com/FariaHuqOaishi"><i class="fa fa-twitter"></i></a>
							<a href="https://www.linkedin.com/in/faria-huq-058b2a145/"><i class="fa fa-linkedin"></i></a>
							<a href="https://github.com/oaishi"><i class="fa fa-github"></i></a>
							<a href="https://www.instagram.com/diy_of_oaishi/"><i class="fa fa-instagram"></i></a>
                        </div>
                    </div>
                </div>
            </div>
            <div class="row footer_bottom justify-content-center">
                <p class="col-lg-8 col-sm-12 footer-text">
                    <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
Copyright &copy;<script>document.write(new Date().getFullYear());</script> Faria Huq | Based on a template by <a href="https://colorlib.com" target="_blank">Colorlib</a>
<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --></p>
            </div>
        </div>
    </footer>
    <!--================End Footer Area =================-->
    
		<!-- Optional JavaScript -->
		<!-- jQuery first, then Popper.js, then Bootstrap JS -->
		<script src="js/jquery-3.2.1.min.js"></script>
		<script src="js/popper.js"></script>
		<script src="js/bootstrap.min.js"></script>
		<script src="js/stellar.js"></script>
		<script src="vendors/lightbox/simpleLightbox.min.js"></script>
		<script src="vendors/nice-select/js/jquery.nice-select.min.js"></script>
		<script src="vendors/isotope/imagesloaded.pkgd.min.js"></script>
		<script src="vendors/isotope/isotope-min.js"></script>
		<script src="vendors/owl-carousel/owl.carousel.min.js"></script>
		<script src="js/jquery.ajaxchimp.min.js"></script>
		<script src="js/mail-script.js"></script>
		<script src="js/theme.js"></script>
	</body>
</html>